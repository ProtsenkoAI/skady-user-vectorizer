{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0b3aa19-f9b0-413c-823f-c35236c4508a",
   "metadata": {},
   "source": [
    "# TODO\n",
    "1. move most of the .md text to the habr post, leave here only code comments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb58d338-c913-46b9-97fb-d1e11f16ae02",
   "metadata": {},
   "source": [
    "### Group2vec\n",
    "**What?**: The notebook demostrates how to use subscriptions of users that we've crawled from social networks. We will train word2vec model, but instead of tokens will use groups\n",
    "\n",
    "**Data used**: I use open data of users from VK social network (popular in Russia, Ukrain, etc). Data crawled using [Suvec VK crawl engine](https://github.com/ProtsenkoAI/skady-user-vectorizer), [Skady ward - crawl GUI](https://github.com/ProtsenkoAI/skady-ward), both instruments I have developed myself\n",
    "\n",
    "**Why?** Because then we can get knowledge about groups and their users in social networks, similarly to how we analyze texts and their authors in NLP. For example, if you want to train RecSys that will work for new users of your service, you can apply group2vec to get some user features without interactions\n",
    "\n",
    "**Why word2vec and not BERT?**: this is simple example of how you can use crawled data. Of course, BERT and other SOTA-closer methods can icrease metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850fb3bf-ccb3-42c4-9c46-9b6e06b196b7",
   "metadata": {},
   "source": [
    "### 1. Set things up: import packages, load data, set variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "81b7e45f-71a8-4456-bfde-64302938bbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from time import time\n",
    "from typing import List, Union, Callable\n",
    "\n",
    "import gensim\n",
    "import vk_api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6208d606-07d6-4f34-b732-a362e717ad1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"./data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9241d5d-ebbd-40fb-bdf4-c77cf971c89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_pth = os.path.join(DATA_PATH, \"parsed_data.json\")\n",
    "\n",
    "with open(parsed_pth) as f:\n",
    "    users_data = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ddb446-831d-4f54-82f7-cf68eecc99ee",
   "metadata": {},
   "source": [
    "### 2. Watch in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32390167-05e2-4e85-a16e-1a95efff3b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 11767 users (text analog for NLP)\n",
      "They subscribed to 1703395 groups (token analog for NLP)\n"
     ]
    }
   ],
   "source": [
    "print(f\"We have {len(users_data)} users (text analog for NLP)\")\n",
    "\n",
    "nb_of_groups = 0\n",
    "for user_id, user_data in users_data.items():\n",
    "    nb_of_groups += len(user_data[\"groups\"])\n",
    "    \n",
    "print(f\"They subscribed to {nb_of_groups} groups (token analog for NLP)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0651a533-016f-49af-bb96-ec15e6605101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Each user has data about: friends and groups\n",
      "'Friends' is list of other users ids:  [10648769, 69462006, 133486963, 140577913, 143059696]\n",
      "'Groups' is list of groups ids:  [75065732, 74938476, 78426877, 79562569, 81212949]\n"
     ]
    }
   ],
   "source": [
    "some_user_id = next(iter(users_data.keys()))\n",
    "some_user_data = users_data[some_user_id]\n",
    "\n",
    "print(\"Each user has data about:\", \" and \".join(some_user_data.keys()))\n",
    "print(\"'Friends' is list of other users ids: \", some_user_data[\"friends\"][:5])\n",
    "print(\"'Groups' is list of groups ids: \", some_user_data[\"groups\"][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da992117-f156-4fc9-8b9d-1fd0f85c3c62",
   "metadata": {},
   "source": [
    "#### Intuition of group2vec\n",
    "Herinafter we treat groups as \"tokens\" and \"users\" as documents.\n",
    "\n",
    "**The idea of word2vec is**: if 2 tokens are met in similar contexts, their meaning is similar. \n",
    "\n",
    "**The idea of group2vec is**: if 2 groups are met in subscriptions of similar users (with a lot of common groups) this groups are similar.\n",
    "\n",
    "**Then** as word2vec appliers make text embedding averaging words embeddings, we make users embeddings averaging groups' ones\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b368ed80-bada-456f-b4b7-d7b334f4efd3",
   "metadata": {},
   "source": [
    "### 3. Prepare data for word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "62c0796c-c449-4318-8fb7-e80377b369f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "for user_data in users_data.values():\n",
    "    # make strings because of gensim requirements\n",
    "    document = [str(group) for group in user_data[\"groups\"]]\n",
    "    corpus.append(document)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da6d3ed-37e9-48a2-bcd5-5af2bef98f94",
   "metadata": {},
   "source": [
    "Note: window of w2v is very large because groups don't have order, unlike words in text. \n",
    "Thus when model predicts a group, it can get information about any other group in user subscriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5a56f27c-bbd1-4c41-a572-d812198bf3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = gensim.models.Word2Vec(min_count=20,\n",
    "                                 window=100,\n",
    "                                 vector_size=300,\n",
    "                                 sample=6e-5, # downsampling popular groups\n",
    "                                 alpha=0.03, \n",
    "                                 min_alpha=0.0007, \n",
    "                                 negative=20,\n",
    "                                 workers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "34eaf2bd-215b-4c82-bd71-965ecbf81015",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.build_vocab(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "25063aaf-05a1-4256-9d0b-a8de51a9afd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train the model: 4.58 mins\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "\n",
    "w2v_model.train(corpus, total_examples=w2v_model.corpus_count, epochs=30, report_delay=1)\n",
    "\n",
    "print('Time to train the model: {} mins'.format(round((time() - t) / 60, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4495467e-50bd-4472-9d80-f1e9b9eb4819",
   "metadata": {},
   "source": [
    "### 4. Test trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7e154d-2a9d-44e2-9d80-b015464f82e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# authorizing in vk to get group names by ids\n",
    "session = vk_api.VkApi(token=input(\"Enter your access token for vk\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ccf2bc35-523d-4432-b6c7-88aeed8d7ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_groups_names(group_ids: List[str]):\n",
    "    group_ids_encoded = \",\".join(group_ids)\n",
    "    resp = session.method(\"groups.getById\", values={\"group_ids\": group_ids_encoded, \"fields\": \"name\"})\n",
    "    \n",
    "    names = [group[\"name\"] for group in resp]\n",
    "    return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "31c309c4-a277-48f0-b8a5-55b09feebc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_wv_method_print_res(group_id_or_ids: Union[str, List[str]], wv_method: Callable):\n",
    "    if isinstance(group_id_or_ids, str):\n",
    "        group_ids = [group_id_or_ids]\n",
    "    else:\n",
    "        group_ids = group_id_or_ids\n",
    "        \n",
    "    model_preds = wv_method(group_ids)\n",
    "    similar_groups_ids = [group_id for group_id, sim_score in model_preds]\n",
    "    \n",
    "    groups_names = get_groups_names(group_ids + similar_groups_ids)\n",
    "    \n",
    "    src_group_name = groups_names[:len(group_ids)]\n",
    "    group_names = groups_names[len(group_id_or_ids):]\n",
    "    print(f\"Similar groups for groups {src_group_name}:\")\n",
    "    print(\"\\n\".join(groups_names))\n",
    "    \n",
    "def find_similar(group_id_or_ids, model: gensim.models.Word2Vec):\n",
    "    return apply_wv_method_print_res(group_id_or_ids, model.wv.most_similar)\n",
    "\n",
    "def find_one_out(group_ids, model: gensim.models.Word2Vec):\n",
    "    return apply_wv_method_print_res(group_ids, model.wv.doesnt_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "6074e507-b489-4ec0-8776-4558be0e9026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar groups for groups ['godnotent']:\n",
      "godnotent\n",
      "киберпанк, который мы заслужили\n",
      "абстрактные мемы для элиты всех сортов | АМДЭВС\n",
      "Swipe Right\n",
      "с каждым днем все радостнее жить\n",
      "романтика городских окраин\n",
      "Даркнет, который мы заслужили\n",
      "вsратые животные\n",
      "ресунки\n",
      "Физика для ебанов\n",
      "$$$ DANK MEMES $$$ AYY LMAO $$$\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-120-8166f6b3f1a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# TODO: split wv_method to many methods\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfind_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"109125388\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mw2v_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfind_one_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"109125388\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"128176420\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"72495085\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mw2v_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-118-80fdb9fc820d>\u001b[0m in \u001b[0;36mfind_one_out\u001b[0;34m(group_ids, model)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfind_one_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWord2Vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mapply_wv_method_print_res\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoesnt_match\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-118-80fdb9fc820d>\u001b[0m in \u001b[0;36mapply_wv_method_print_res\u001b[0;34m(group_id_or_ids, wv_method)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mmodel_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwv_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0msimilar_groups_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgroup_id\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mgroup_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msim_score\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_preds\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mgroups_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_groups_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup_ids\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msimilar_groups_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-118-80fdb9fc820d>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mmodel_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwv_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0msimilar_groups_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgroup_id\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mgroup_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msim_score\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_preds\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mgroups_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_groups_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup_ids\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msimilar_groups_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "# TODO: split wv_method to many methods\n",
    "find_similar(\"109125388\", model=w2v_model)\n",
    "find_one_out([\"109125388\", \"128176420\", \"72495085\"], model=w2v_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f215a8-4467-422b-84ae-4a9dbff610e7",
   "metadata": {},
   "source": [
    "### TODO: TSNE of clusters, list of groups, several clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba869c5-f7ad-439e-8d60-ebebb4bdc9ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
